# 🚀 使用和部署指南

本指南将教你如何使用训练好的模型进行裂缝检测，以及如何部署 Web 应用。

## 📚 目录

1. [快速开始](#快速开始)
2. [测试模型](#测试模型)
3. [Web 应用使用](#web-应用使用)
4. [部署到服务器](#部署到服务器)
5. [API 调用](#api-调用)
6. [常见问题](#常见问题)

---

## 快速开始

### 方法 1: 使用启动脚本（最简单）

#### Linux / Mac

```bash
bash run_linux.sh
```

#### Windows

双击运行 `run_windows.bat` 或在命令行中执行：

```cmd
run_windows.bat
```

### 方法 2: 手动启动

```bash
# 1. 确保依赖已安装
pip install -r requirements.txt

# 2. 启动 Web 应用
python app.py
```

### 启动成功标志

看到以下输出表示启动成功：

```
使用设备: cuda
成功加载模型: best_model.pth

==================================================
启动道路裂缝检测系统...
==================================================

Running on local URL:  http://127.0.0.1:7860
Running on public URL: https://xxxxx.gradio.live

To create a public link, set `share=True` in `launch()`.
```

**访问方式**：
- **本地访问**: http://127.0.0.1:7860
- **局域网访问**: http://你的IP:7860
- **公网访问**: 使用显示的 gradio.live 链接（临时，24小时有效）

---

## 测试模型

### 使用测试脚本

```bash
python model_test.py
```

### 测试脚本功能

1. **加载测试集**：从 `data/test/` 读取图片
2. **批量预测**：对所有测试图片进行裂缝检测
3. **生成可视化**：保存原图、预测结果、真实标注的对比图
4. **计算指标**：输出整体 IoU、准确率等

### 查看测试结果

结果保存在 `test_results/` 文件夹：

```
test_results/
├── sample_0_comparison.png    # 第1张对比图
├── sample_1_comparison.png    # 第2张对比图
├── sample_2_comparison.png
└── ...
```

**对比图包含**：
- **左图**：原始图片
- **中图**：模型预测的裂缝（白色=裂缝）
- **右图**：真实标注

### 评估指标解读

```
测试集总体指标:
平均 IoU: 0.8234
准确率: 92.45%
召回率: 87.32%
F1分数: 89.81%
```

**指标说明**：

| 指标 | 含义 | 好坏标准 |
|------|------|----------|
| **IoU** | 预测与真实标注的重叠度 | > 0.7 优秀，> 0.5 良好 |
| **准确率** | 预测正确的像素占比 | > 90% 优秀 |
| **召回率** | 真实裂缝被检测出的比例 | > 85% 良好 |
| **F1分数** | 准确率和召回率的综合 | > 85% 优秀 |

---

## Web 应用使用

### 界面介绍

启动应用后，浏览器会打开如下界面：

```
┌─────────────────────────────────────────────────┐
│        🛣️ 道路裂缝检测系统                      │
│    基于 U-Net 深度学习模型的道路裂缝自动检测    │
├─────────────────────────────────────────────────┤
│                                                 │
│  [上传道路图片]            [检测结果]          │
│   ┌───────────┐             ┌───────────┐      │
│   │           │             │           │      │
│   │  点击或   │             │  二值mask │      │
│   │  拖拽上传 │             │           │      │
│   │           │             └───────────┘      │
│   └───────────┘                                │
│                              ┌───────────┐      │
│   □ 显示叠加图               │           │      │
│   透明度: ├─────┤ 0.5        │  叠加图   │      │
│                              │           │      │
│   [🔍 开始检测]              └───────────┘      │
│                                                 │
│                              ### 检测结果       │
│                              - 裂缝占比: 3.45%  │
│                              - 严重程度: 轻微   │
└─────────────────────────────────────────────────┘
```

### 使用步骤

#### 步骤 1: 上传图片

**方式一**：点击上传框选择图片
**方式二**：直接拖拽图片到上传框

**支持格式**：JPG, PNG, JPEG

#### 步骤 2: 调整参数（可选）

展开"高级设置"：

- **显示叠加图**：勾选后会显示裂缝叠加在原图上的效果
- **叠加透明度**：调整红色标记的透明度（0=完全透明，1=完全不透明）

#### 步骤 3: 开始检测

点击 **🔍 开始检测** 按钮

#### 步骤 4: 查看结果

系统会显示三个结果：

1. **检测结果（二值mask）**
   - 黑色 = 正常路面
   - 白色 = 检测到的裂缝

2. **叠加可视化**
   - 原图上标注红色区域
   - 红色 = 裂缝位置

3. **检测报告**
   ```markdown
   ### 检测结果

   - **裂缝占比**: 3.45%
   - **严重程度**: 轻微
   - **图像尺寸**: 1920 × 1080
   - **检测分辨率**: 224 × 224
   ```

### 严重程度判定标准

| 裂缝占比 | 严重程度 | 建议 |
|---------|---------|------|
| < 0.1% | 未检测到明显裂缝 | 正常 |
| 0.1% - 5% | 检测到裂缝 - 轻微 | 关注 |
| 5% - 10% | 检测到裂缝 - 中等 | 尽快修复 |
| > 10% | 检测到裂缝 - 严重 | 立即处理 |

### 批量检测

如果需要批量处理多张图片，可以使用 Python 脚本：

```python
# batch_detect.py
from app import CrackDetectionApp
from PIL import Image
import os

# 初始化应用
app = CrackDetectionApp()

# 批量处理
input_dir = "待检测图片/"
output_dir = "检测结果/"
os.makedirs(output_dir, exist_ok=True)

for img_file in os.listdir(input_dir):
    if img_file.endswith(('.jpg', '.png', '.jpeg')):
        # 读取图片
        img_path = os.path.join(input_dir, img_file)
        image = Image.open(img_path)

        # 检测
        mask, overlay, report = app.process_image(image)

        # 保存结果
        Image.fromarray(mask).save(
            os.path.join(output_dir, f"{img_file}_mask.png")
        )
        Image.fromarray(overlay).save(
            os.path.join(output_dir, f"{img_file}_overlay.png")
        )

        print(f"✓ 已处理: {img_file}")

print("批量检测完成！")
```

运行：
```bash
python batch_detect.py
```

---

## 部署到服务器

### 部署方案 1: 本地网络部署

适合在局域网内使用（如公司内网）。

#### 配置步骤

1. **修改 app.py**
```python
# 找到这部分代码
demo.launch(
    server_name="0.0.0.0",  # 允许外部访问
    server_port=7860,        # 端口号
    share=False,             # 不生成公网链接
    show_error=True
)
```

2. **启动应用**
```bash
python app.py
```

3. **查找服务器 IP**
```bash
# Linux/Mac
ifconfig | grep "inet "

# Windows
ipconfig
```

4. **局域网内访问**
```
http://服务器IP:7860
例如: http://192.168.1.100:7860
```

### 部署方案 2: 云服务器部署

适合需要公网访问的场景。

#### 使用 AWS / 阿里云 / 腾讯云

1. **创建云服务器**
   - 选择 GPU 实例（推荐）或 CPU 实例
   - 操作系统：Ubuntu 20.04 或更高

2. **安装环境**
```bash
# 更新系统
sudo apt update && sudo apt upgrade -y

# 安装 Python
sudo apt install python3.8 python3-pip -y

# 克隆项目
git clone https://github.com/Makeprograss/U-net_to_check_road_crake.git
cd U-net_to_check_road_crake

# 安装依赖
pip3 install -r requirements.txt
```

3. **下载模型**
```bash
# 从训练服务器传输模型，或使用预训练模型
scp user@训练服务器:/path/to/best_model.pth ./
```

4. **配置防火墙**
```bash
# 开放 7860 端口
sudo ufw allow 7860
```

5. **后台运行**
```bash
# 使用 nohup 后台运行
nohup python3 app.py > app.log 2>&1 &

# 或使用 screen
screen -S crack_detection
python3 app.py
# 按 Ctrl+A 然后 D 退出screen

# 查看日志
tail -f app.log
```

6. **访问应用**
```
http://服务器公网IP:7860
```

### 部署方案 3: Docker 部署

适合需要快速部署和迁移的场景。

#### 创建 Dockerfile

```dockerfile
# Dockerfile
FROM python:3.8-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# 复制项目文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# 暴露端口
EXPOSE 7860

# 启动应用
CMD ["python", "app.py"]
```

#### 构建和运行

```bash
# 构建镜像
docker build -t crack-detection .

# 运行容器
docker run -d \
  --name crack-app \
  -p 7860:7860 \
  -v $(pwd)/data:/app/data \
  crack-detection

# 查看日志
docker logs -f crack-app
```


## 常见问题

### Q1: 启动后无法访问 Web 界面

**检查步骤**：

1. **确认程序正在运行**
```bash
ps aux | grep app.py
```

2. **检查端口是否被占用**
```bash
# Linux
lsof -i :7860

# Windows
netstat -ano | findstr :7860
```

3. **尝试更改端口**
```python
demo.launch(server_port=8080)  # 改为 8080
```

### Q2: 模型检测不准确

**可能原因和解决方法**：

1. **图片质量问题**
   - 确保图片清晰、光线充足
   - 避免过度模糊或过暗的图片

2. **模型训练不充分**
   - 增加训练数据
   - 延长训练时间
   - 参考 [模型训练指南](./02_模型训练指南.md)

3. **场景差异大**
   - 训练数据与测试数据差异大
   - 需要用相似场景的数据重新训练

### Q3: 处理速度慢

**优化方法**：

1. **使用 GPU**
```python
# 确认 CUDA 可用
python -c "import torch; print(torch.cuda.is_available())"
```

2. **减小输入图片尺寸**
```python
# 在 app.py 中修改
transforms.Resize((224, 224))  # 已经是最小了
```

3. **批量处理**
```python
# 使用批处理脚本（上面提供的 batch_detect.py）
```

### Q4: 内存占用过高

**解决方法**：

1. **释放不用的资源**
```python
import gc
gc.collect()
torch.cuda.empty_cache()  # 如果使用GPU
```

2. **减小 batch size**
```python
# 在推理时使用更小的batch
```

### Q5: 如何更新模型？

1. **训练新模型**
```bash
python model_train.py
```

2. **替换模型文件**
```bash
cp best_model.pth old_model.pth  # 备份旧模型
# 新模型会自动保存为 best_model.pth
```

3. **重启应用**
```bash
# 停止当前应用
pkill -f app.py

# 重新启动
python app.py
```

---

## 性能优化建议

### 1. 模型优化

**模型量化**（减小模型大小，加快推理）：
```python
import torch

model = UNet(n_channels=3, n_classes=2)
model.load_state_dict(torch.load('best_model.pth'))
model.eval()

# 转换为量化模型
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# 保存量化模型
torch.save(quantized_model.state_dict(), 'model_quantized.pth')
```

### 2. 缓存机制

对于重复检测相同图片，可以添加缓存：

```python
import hashlib
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_predict(image_hash):
    # 根据图片hash缓存结果
    pass
```

### 3. 并发处理

使用多进程处理多个请求：

```python
demo.launch(
    server_name="0.0.0.0",
    server_port=7860,
    share=False,
    max_threads=4  # 允许4个并发请求
)
```

---

## 下一步

了解代码实现细节，请查看 [代码详解](./04_代码详解.md)！

---

**部署成功！** 遇到问题请查看 Issues 或提交新问题。
